{
  
    
        "post0": {
            "title": "Deep Convolutional Auto Encoders - Part 2",
            "content": "Introduction . In the first part I reimplemented the convolutional auto encoder from TimeCluster by Ali et al This time, I will adapt the model to handle all 300 flock agents. . In this notebook a 1D convolutional approach is evaluated . Data Noramlisation and preperation . Normalise the data the same way as before; into the range [0, 1] as per the paper. . We then create a sliding window using the defaults from the paper where stride = 1 and window_size = 60 . Then we shuffle the data and split into train, validate and test subsets . function normalise(M) min = minimum(minimum(eachcol(M))) max = maximum(maximum(eachcol(M))) return (M .- min) ./ (max - min) end normalised = Array(df) |&gt; normalise window_size = 60 data = slidingwindow(normalised&#39;,window_size,stride=1) train, validate, test = splitobs(shuffleobs(data), (0.7,0.2)); . Define the encoder and decoder . We can define the network shape in a couple of different ways: . Keeping the convolution 1 dimentional and simply increasing the number of features from 3 to 900 (3 * num_of_agents) | Using 2D convolution: window_size X num_of_agents x dimensions (3) x batch | . In this notebook we will look at the 1D approach. . 1D Convolution . Adjusted the dimension expansion from ≈ 21x to 10x Also an aditional Conv/ConvTranspose step is added to reduce the dimensionality of the encoded space further . function create_ae_1d() # Define the encoder and decoder networks encoder = Chain( # 60x900xb Conv((9,), 900 =&gt; 9000, relu; pad = SamePad()), MaxPool((2,)), # 30x9000xb Conv((5,), 9000 =&gt; 4500, relu; pad = SamePad()), MaxPool((2,)), # 15x4500xb Conv((5,),4500 =&gt; 2250, relu; pad = SamePad()), # 15x2250xb MaxPool((3,)), Conv((3,),2250 =&gt; 1000, relu; pad = SamePad()), Conv((3,),1000 =&gt; 100, relu; pad = SamePad()), # 5x100xb Flux.flatten, Dense(500,100) ) decoder = Chain( Dense(100,500), (x -&gt; reshape(x, 5,100,:)), # 5x100xb ConvTranspose((3,), 100 =&gt; 1000, relu; pad = SamePad()), ConvTranspose((3,), 1000 =&gt; 2250, relu; pad = SamePad()), Upsample((3,)), # 15x2250xb ConvTranspose((5,), 2250 =&gt; 4500, relu; pad = SamePad()), Upsample((2,)), # 30x4500xb ConvTranspose((5,), 4500 =&gt; 9000, relu; pad = SamePad()), Upsample((2,)), # 60x9000xb ConvTranspose((9,), 9000 =&gt; 900, relu; pad = SamePad()), # 60x900xb ) return (encoder, decoder) end . create_ae_1d (generic function with 1 method) . Training . Training needs to be slightly adapted for each version of model we use. Also we now use train/validation/test sets for more accurate performance calculation. I&#39;ve also added learning rate adjustment and automatic model saving. . function save_model(m, epoch, loss) model_row = LegolasFlux.ModelRow(; weights = fetch_weights(cpu(m)),architecture_version=1, loss=0.0001) write_model_row(&quot;1d_300_model-$epoch-$loss.arrow&quot;, model_row) end function rearrange_1D(x) permutedims(cat(x..., dims=3), [2,1,3]) end function train_model_1D!(model, train, validate, opt; epochs=20, bs=16, dev=Flux.gpu) ps = Flux.params(model) local train_loss, train_loss_acc local validate_loss, validate_loss_acc local last_improvement = 0 local prev_best_loss = 0.01 local improvement_thresh = 5.0 validate_losses = Vector{Float64}() for e in 1:epochs train_loss_acc = 0.0 for x in eachbatch(train, size=bs) x = rearrange_1D(x) |&gt; dev gs = Flux.gradient(ps) do train_loss = Flux.Losses.mse(model(x),x) return train_loss end train_loss_acc += train_loss Flux.update!(opt, ps, gs) end validate_loss_acc = 0.0 for y in eachbatch(validate, size=bs) y = rearrange_1D(y) |&gt; dev validate_loss = Flux.Losses.mse(model(y), y) validate_loss_acc += validate_loss end validate_loss_acc = round(validate_loss_acc / (length(validate)/bs); digits=6) train_loss_acc = round(train_loss_acc / (length(train)/bs) ;digits=6) if validate_loss_acc &lt; 0.001 if validate_loss_acc &lt; prev_best_loss @info &quot;new best accuracy $validate_loss_acc saving model...&quot; save_model(model, e, validate_loss_acc) last_improvement = e prev_best_loss = validate_loss_acc elseif (e - last_improvement) &gt;= improvement_thresh &amp;&amp; opt.eta &gt; 1e-5 @info &quot;Not improved in $improvement_thresh epochs. Dropping learning rate to $(opt.eta / 2.0)&quot; opt.eta /= 2.0 last_improvement = e # give it some time to improve improvement_thresh = improvement_thresh * 1.5 elseif (e - last_improvement) &gt;= 15 @info &quot;Not improved in 15 epochs. Converged I guess&quot; break end end push!(validate_losses, validate_loss_acc) println(&quot;Epoch $e/$epochs t train loss: $train_loss_acc t validate loss: $validate_loss_acc&quot;) end validate_losses end . train_model_1D! (generic function with 1 method) . losses_0001 = train_model_1D!(model, train, validate, Flux.Optimise.ADAM(0.0001); epochs=200, bs=48); . ┌ Warning: The specified values for size and/or count will result in 21 unused data points └ @ MLDataPattern /opt/julia/packages/MLDataPattern/KlSmO/src/dataview.jl:205 . Epoch 1/200 train loss: 0.430836 validate loss: 0.057712 Epoch 2/200 train loss: 0.055009 validate loss: 0.051833 Epoch 3/200 train loss: 0.053515 validate loss: 0.051719 Epoch 4/200 train loss: 0.053483 validate loss: 0.051669 Epoch 5/200 train loss: 0.053481 validate loss: 0.051648 Epoch 6/200 train loss: 0.05348 validate loss: 0.051622 Epoch 7/200 train loss: 0.053478 validate loss: 0.051622 Epoch 8/200 train loss: 0.053471 validate loss: 0.051615 Epoch 9/200 train loss: 0.053464 validate loss: 0.051602 Epoch 10/200 train loss: 0.053461 validate loss: 0.051603 Epoch 11/200 train loss: 0.053447 validate loss: 0.051597 Epoch 12/200 train loss: 0.053427 validate loss: 0.051574 Epoch 13/200 train loss: 0.053222 validate loss: 0.050061 Epoch 14/200 train loss: 0.040074 validate loss: 0.033838 Epoch 15/200 train loss: 0.034933 validate loss: 0.033222 Epoch 16/200 train loss: 0.029958 validate loss: 0.018663 Epoch 17/200 train loss: 0.015721 validate loss: 0.012654 Epoch 18/200 train loss: 0.011821 validate loss: 0.010214 Epoch 19/200 train loss: 0.009049 validate loss: 0.007028 Epoch 20/200 train loss: 0.006481 validate loss: 0.005952 Epoch 21/200 train loss: 0.004894 validate loss: 0.003345 Epoch 22/200 train loss: 0.002088 validate loss: 0.001259 Epoch 23/200 train loss: 0.001 validate loss: 0.001243 . ┌ Info: new best accuracy 0.000762 saving model... └ @ Main In[9]:41 . Epoch 24/200 train loss: 0.000691 validate loss: 0.000762 . ┌ Info: new best accuracy 0.000597 saving model... └ @ Main In[9]:41 . Epoch 25/200 train loss: 0.000683 validate loss: 0.000597 . ┌ Info: new best accuracy 0.000309 saving model... └ @ Main In[9]:41 . Epoch 26/200 train loss: 0.000584 validate loss: 0.000309 . ┌ Info: new best accuracy 0.000142 saving model... └ @ Main In[9]:41 . Epoch 27/200 train loss: 0.000244 validate loss: 0.000142 . ┌ Info: new best accuracy 9.1e-5 saving model... └ @ Main In[9]:41 . Epoch 28/200 train loss: 0.000118 validate loss: 9.1e-5 . ┌ Info: new best accuracy 7.4e-5 saving model... └ @ Main In[9]:41 . Epoch 29/200 train loss: 8.6e-5 validate loss: 7.4e-5 . ┌ Info: new best accuracy 6.3e-5 saving model... └ @ Main In[9]:41 . Epoch 30/200 train loss: 7.1e-5 validate loss: 6.3e-5 Epoch 31/200 train loss: 6.5e-5 validate loss: 6.5e-5 . ┌ Info: new best accuracy 5.6e-5 saving model... └ @ Main In[9]:41 . Epoch 32/200 train loss: 6.3e-5 validate loss: 5.6e-5 . ┌ Info: new best accuracy 4.8e-5 saving model... └ @ Main In[9]:41 . Epoch 33/200 train loss: 5.3e-5 validate loss: 4.8e-5 . ┌ Info: new best accuracy 4.2e-5 saving model... └ @ Main In[9]:41 . Epoch 34/200 train loss: 4.6e-5 validate loss: 4.2e-5 . ┌ Info: new best accuracy 3.9e-5 saving model... └ @ Main In[9]:41 . Epoch 35/200 train loss: 4.2e-5 validate loss: 3.9e-5 . ┌ Info: new best accuracy 3.6e-5 saving model... └ @ Main In[9]:41 . Epoch 36/200 train loss: 3.8e-5 validate loss: 3.6e-5 . ┌ Info: new best accuracy 3.3e-5 saving model... └ @ Main In[9]:41 . Epoch 37/200 train loss: 3.5e-5 validate loss: 3.3e-5 . ┌ Info: new best accuracy 3.1e-5 saving model... └ @ Main In[9]:41 . Epoch 38/200 train loss: 3.3e-5 validate loss: 3.1e-5 . ┌ Info: new best accuracy 2.9e-5 saving model... └ @ Main In[9]:41 . Epoch 39/200 train loss: 3.1e-5 validate loss: 2.9e-5 . ┌ Info: new best accuracy 2.7e-5 saving model... └ @ Main In[9]:41 . Epoch 40/200 train loss: 2.9e-5 validate loss: 2.7e-5 Epoch 41/200 train loss: 2.7e-5 validate loss: 2.8e-5 . ┌ Info: new best accuracy 2.6e-5 saving model... └ @ Main In[9]:41 . Epoch 42/200 train loss: 2.7e-5 validate loss: 2.6e-5 Epoch 43/200 train loss: 3.0e-5 validate loss: 2.9e-5 Epoch 44/200 train loss: 6.2e-5 validate loss: 8.7e-5 Epoch 45/200 train loss: 0.000182 validate loss: 0.000175 Epoch 46/200 train loss: 0.000311 validate loss: 0.000224 Epoch 47/200 train loss: 0.00104 validate loss: 0.000602 . ┌ Info: Not improved in 5 epochs. Dropping learning rate to 5.0e-5 └ @ Main In[9]:46 . Epoch 48/200 train loss: 0.000221 validate loss: 5.7e-5 Epoch 49/200 train loss: 3.7e-5 validate loss: 2.6e-5 . ┌ Info: new best accuracy 2.4e-5 saving model... └ @ Main In[9]:41 . Epoch 50/200 train loss: 2.5e-5 validate loss: 2.4e-5 . ┌ Info: new best accuracy 2.2e-5 saving model... └ @ Main In[9]:41 . Epoch 51/200 train loss: 2.2e-5 validate loss: 2.2e-5 . ┌ Info: new best accuracy 2.1e-5 saving model... └ @ Main In[9]:41 . Epoch 52/200 train loss: 2.1e-5 validate loss: 2.1e-5 . ┌ Info: new best accuracy 2.0e-5 saving model... └ @ Main In[9]:41 . Epoch 53/200 train loss: 2.0e-5 validate loss: 2.0e-5 . ┌ Info: new best accuracy 1.9e-5 saving model... └ @ Main In[9]:41 . Epoch 54/200 train loss: 1.9e-5 validate loss: 1.9e-5 . ┌ Info: new best accuracy 1.8e-5 saving model... └ @ Main In[9]:41 . Epoch 55/200 train loss: 1.9e-5 validate loss: 1.8e-5 Epoch 56/200 train loss: 1.8e-5 validate loss: 1.8e-5 . ┌ Info: new best accuracy 1.7e-5 saving model... └ @ Main In[9]:41 . Epoch 57/200 train loss: 1.8e-5 validate loss: 1.7e-5 Epoch 58/200 train loss: 1.7e-5 validate loss: 1.7e-5 . ┌ Info: new best accuracy 1.6e-5 saving model... └ @ Main In[9]:41 . Epoch 59/200 train loss: 1.7e-5 validate loss: 1.6e-5 Epoch 60/200 train loss: 1.7e-5 validate loss: 1.6e-5 Epoch 61/200 train loss: 1.6e-5 validate loss: 1.6e-5 Epoch 62/200 train loss: 1.6e-5 validate loss: 1.6e-5 . ┌ Info: new best accuracy 1.5e-5 saving model... └ @ Main In[9]:41 . Epoch 63/200 train loss: 1.6e-5 validate loss: 1.5e-5 Epoch 64/200 train loss: 1.5e-5 validate loss: 1.5e-5 Epoch 65/200 train loss: 1.5e-5 validate loss: 1.5e-5 Epoch 66/200 train loss: 1.5e-5 validate loss: 1.5e-5 . ┌ Info: new best accuracy 1.4e-5 saving model... └ @ Main In[9]:41 . Epoch 67/200 train loss: 1.5e-5 validate loss: 1.4e-5 Epoch 68/200 train loss: 1.4e-5 validate loss: 1.4e-5 Epoch 69/200 train loss: 1.4e-5 validate loss: 1.4e-5 Epoch 70/200 train loss: 1.4e-5 validate loss: 1.4e-5 . ┌ Info: new best accuracy 1.3e-5 saving model... └ @ Main In[9]:41 . Epoch 71/200 train loss: 1.4e-5 validate loss: 1.3e-5 Epoch 72/200 train loss: 1.4e-5 validate loss: 1.3e-5 Epoch 73/200 train loss: 1.3e-5 validate loss: 1.3e-5 Epoch 74/200 train loss: 1.3e-5 validate loss: 1.3e-5 Epoch 75/200 train loss: 1.3e-5 validate loss: 1.3e-5 . ┌ Info: new best accuracy 1.2e-5 saving model... └ @ Main In[9]:41 . Epoch 76/200 train loss: 1.3e-5 validate loss: 1.2e-5 Epoch 77/200 train loss: 1.2e-5 validate loss: 1.2e-5 Epoch 78/200 train loss: 1.2e-5 validate loss: 1.2e-5 Epoch 79/200 train loss: 1.2e-5 validate loss: 1.2e-5 Epoch 80/200 train loss: 1.2e-5 validate loss: 1.2e-5 . ┌ Info: new best accuracy 1.1e-5 saving model... └ @ Main In[9]:41 . Epoch 81/200 train loss: 1.2e-5 validate loss: 1.1e-5 Epoch 82/200 train loss: 1.1e-5 validate loss: 1.1e-5 Epoch 83/200 train loss: 1.1e-5 validate loss: 1.1e-5 Epoch 84/200 train loss: 1.1e-5 validate loss: 1.1e-5 Epoch 85/200 train loss: 1.1e-5 validate loss: 1.1e-5 Epoch 86/200 train loss: 1.1e-5 validate loss: 1.1e-5 Epoch 87/200 train loss: 1.1e-5 validate loss: 1.1e-5 Epoch 88/200 train loss: 1.1e-5 validate loss: 1.1e-5 Epoch 89/200 train loss: 1.1e-5 validate loss: 1.1e-5 . ┌ Info: Not improved in 5 epochs. Dropping learning rate to 2.5e-5 └ @ Main In[9]:46 ┌ Info: new best accuracy 1.0e-5 saving model... └ @ Main In[9]:41 . Epoch 90/200 train loss: 1.0e-5 validate loss: 1.0e-5 Epoch 91/200 train loss: 1.0e-5 validate loss: 1.0e-5 Epoch 92/200 train loss: 1.0e-5 validate loss: 1.0e-5 Epoch 93/200 train loss: 1.0e-5 validate loss: 1.0e-5 Epoch 94/200 train loss: 1.0e-5 validate loss: 1.0e-5 Epoch 95/200 train loss: 1.0e-5 validate loss: 1.0e-5 Epoch 96/200 train loss: 1.0e-5 validate loss: 1.0e-5 . ┌ Info: new best accuracy 9.0e-6 saving model... └ @ Main In[9]:41 . Epoch 97/200 train loss: 1.0e-5 validate loss: 9.0e-6 Epoch 98/200 train loss: 9.0e-6 validate loss: 9.0e-6 Epoch 99/200 train loss: 9.0e-6 validate loss: 9.0e-6 Epoch 100/200 train loss: 9.0e-6 validate loss: 9.0e-6 Epoch 101/200 train loss: 9.0e-6 validate loss: 9.0e-6 Epoch 102/200 train loss: 9.0e-6 validate loss: 9.0e-6 Epoch 103/200 train loss: 9.0e-6 validate loss: 9.0e-6 Epoch 104/200 train loss: 9.0e-6 validate loss: 9.0e-6 Epoch 105/200 train loss: 9.0e-6 validate loss: 9.0e-6 Epoch 106/200 train loss: 9.0e-6 validate loss: 9.0e-6 Epoch 107/200 train loss: 9.0e-6 validate loss: 9.0e-6 Epoch 108/200 train loss: 9.0e-6 validate loss: 9.0e-6 Epoch 109/200 train loss: 9.0e-6 validate loss: 9.0e-6 . ┌ Info: Not improved in 5 epochs. Dropping learning rate to 1.25e-5 └ @ Main In[9]:46 . Epoch 110/200 train loss: 9.0e-6 validate loss: 9.0e-6 Epoch 111/200 train loss: 9.0e-6 validate loss: 9.0e-6 . ┌ Info: new best accuracy 8.0e-6 saving model... └ @ Main In[9]:41 . Epoch 112/200 train loss: 8.0e-6 validate loss: 8.0e-6 Epoch 113/200 train loss: 8.0e-6 validate loss: 8.0e-6 Epoch 114/200 train loss: 8.0e-6 validate loss: 8.0e-6 Epoch 115/200 train loss: 8.0e-6 validate loss: 8.0e-6 Epoch 116/200 train loss: 8.0e-6 validate loss: 8.0e-6 Epoch 117/200 train loss: 8.0e-6 validate loss: 8.0e-6 Epoch 118/200 train loss: 8.0e-6 validate loss: 8.0e-6 Epoch 119/200 train loss: 8.0e-6 validate loss: 8.0e-6 Epoch 120/200 train loss: 8.0e-6 validate loss: 8.0e-6 Epoch 121/200 train loss: 8.0e-6 validate loss: 8.0e-6 Epoch 122/200 train loss: 8.0e-6 validate loss: 8.0e-6 Epoch 123/200 train loss: 8.0e-6 validate loss: 8.0e-6 Epoch 124/200 train loss: 8.0e-6 validate loss: 8.0e-6 Epoch 125/200 train loss: 8.0e-6 validate loss: 8.0e-6 Epoch 126/200 train loss: 8.0e-6 validate loss: 8.0e-6 . ┌ Info: Not improved in 10 epochs. Converged I guess └ @ Main In[9]:51 . . Results . We managed to get a validation loss of 8.0e-6, taking a 900x60 space down into a 1x100 vector . Lets see what this means in practical terms by comparing an input to an output: . test_data = rand(test) create_gif_from_raw(test_data) . ┌ Info: Saved animation to │ fn = /notebooks/anim_fps30.gif └ @ Plots /opt/julia/packages/Plots/LSKOd/src/animation.jl:114 . input = Flux.unsqueeze(test_data&#39;, 3) output = new_model(input) output = reshape(output, 60,900)&#39; create_gif_from_raw(output) . ┌ Info: Saved animation to │ fn = /notebooks/anim_fps30.gif └ @ Plots /opt/julia/packages/Plots/LSKOd/src/animation.jl:114 . Conclusion . After a few hours of training on GPU, we can now reasonably encode the movement of the whole swarm (300 agents) over 60 timesteps into 100 variables. However, I want to reduce that encoding even further into ~10 parameters that can be used to sonify the dynamics. . Next time I will see how much further a can reduce the latent space - as well as seeing how useful other DR methods are when applied to the latent space. .",
            "url": "https://maxworgan.github.io/blog/dimension%20reduction/auto-encoder/swarm/2022/02/06/DCAE_Part_2.html",
            "relUrl": "/dimension%20reduction/auto-encoder/swarm/2022/02/06/DCAE_Part_2.html",
            "date": " • Feb 6, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Deep Convolutional Auto Encoders - Part 1",
            "content": "Introduction . My aim is to try and encode a simulated swarm into a lower dimentional representation so I can identify interesting parameters with which to map into a sound generating system. . My initial research into reducing complex time-series data lead me to a paper by Ali et al . They use convolutional layers in an auto encoder to do dimension reduction on various time series data. . This seemed like a good place to start, so initially I am just documenting my attempt to recreate their research, using a single agents coordinates in 3d space to match the shape of their model. . Details . Their approach uses 1D Convolution and the data split into interleaved sliding windows of data: . They used a 60 frame window and 3 readings from accelerometers resulting in a 60x3 shape input image. . As a test of their approach I used a single agents movement data to match the original model specifications. . Data is captured from a separate flocking simulation (source available on my github soon) of 300 agents over approximately 30 seconds. . using Flux, CSV, DataFrames, MLDataPattern, CUDA, Plots, WebIO; plotly() . Resolving package versions... No Changes to `~/Documents/JuliaProjects/Swarm/Project.toml` No Changes to `~/Documents/JuliaProjects/Swarm/Manifest.toml` . Plots.PlotlyBackend() . df = DataFrame(CSV.File(&quot;$(datadir())/exp_raw/data.csv&quot;; types=Float32)) df = df[:,1:3] plot(df[:,1],df[:,2], df[:,3]) . We can treat this 3D data as 3 separate 1D data points, matching the original TimeCluster data shape . plot(df[:,1], label=&quot;x&quot;) plot!(df[:,2], label=&quot;y&quot;) plot!(df[:,3], label=&quot;z&quot;) . Data Noramlisation and preperation . Normalise the data into the range [0, 1] as per the paper. We then create a sliding window using the defaults from the paper where stride = 1 and window_size = 60 . function normalise(M) min = minimum(minimum(eachcol(M))) max = maximum(maximum(eachcol(M))) return (M .- min) ./ (max - min) end normalised = Array(df) |&gt; normalise window_size = 60 data = slidingwindow(normalised&#39;,window_size,stride=1); . Define the encoder and decoder . We create the auto-encoder network as per the paper . function create_ae() # Define the encoder and decoder networks encoder = Chain( # 60x3xb Conv((10,), 3 =&gt; 64, relu; pad = SamePad()), MaxPool((2,)), # 30x64xb Conv((5,), 64 =&gt; 32, relu; pad = SamePad()), MaxPool((2,)), # 15x32xb Conv((5,), 32 =&gt; 12, relu; pad = SamePad()), MaxPool((3,)), # 5x12xb Flux.flatten, Dense(window_size,window_size) ) decoder = Chain( # input 60 (x -&gt; reshape(x, (floor(Int, (window_size / 12)),12,:))), # 5x12xb ConvTranspose((5,), 12 =&gt; 32, relu; pad = SamePad()), Upsample((3,)), # 15x32xb ConvTranspose((5,), 32 =&gt; 64, relu; pad = SamePad()), Upsample((2,)), # 30x64xb ConvTranspose((10,), 64 =&gt; 3, relu; pad = SamePad()), Upsample((2,)), # 60x3xb ) return Chain(encoder, decoder) end . create_ae (generic function with 1 method) . Training . In keeping with the paper we use the Mean Square Error loss function and the ADAM optimiser . function train_model!(model, data, opt; epochs=20, bs=16, dev=Flux.gpu) model = model |&gt; dev ps = params(model) t = shuffleobs(data) local l losses = Vector{Float64}() for e in 1:epochs for x in eachbatch(t, size=bs) # bs[(3, 60)] x = cat(x..., dims=3) # bs x 3 x 60 x = permutedims(x, [2,1,3]) # 60 x 3 x bs gs = gradient(ps) do l = loss(model(x),x) end Flux.update!(opt, ps, gs) end l = round(l;digits=6) push!(losses, l) println(&quot;Epoch $e/$epochs - train loss: $l&quot;) end model = model |&gt; cpu; losses end . train_model! (generic function with 1 method) . loss(x,y) = Flux.Losses.mse(x, y) opt = Flux.Optimise.ADAM(0.00005) epochs = 100 . loss (generic function with 1 method) . model = create_ae() losses_01 = train_model!(model, data, opt; epochs=epochs); . Epoch 1/100 - train loss: 0.018689 Epoch 2/100 - train loss: 0.004161 Epoch 3/100 - train loss: 0.002182 Epoch 4/100 - train loss: 0.001568 Epoch 5/100 - train loss: 0.001264 Epoch 6/100 - train loss: 0.001071 Epoch 7/100 - train loss: 0.000899 Epoch 8/100 - train loss: 0.000703 Epoch 9/100 - train loss: 0.0005 Epoch 10/100 - train loss: 0.000352 Epoch 11/100 - train loss: 0.00028 Epoch 12/100 - train loss: 0.000236 Epoch 13/100 - train loss: 0.000202 Epoch 14/100 - train loss: 0.000178 Epoch 15/100 - train loss: 0.000159 Epoch 16/100 - train loss: 0.000142 Epoch 17/100 - train loss: 0.000127 Epoch 18/100 - train loss: 0.000113 Epoch 19/100 - train loss: 0.000101 Epoch 20/100 - train loss: 9.2e-5 Epoch 21/100 - train loss: 8.3e-5 Epoch 22/100 - train loss: 7.5e-5 Epoch 23/100 - train loss: 6.8e-5 Epoch 24/100 - train loss: 6.3e-5 Epoch 25/100 - train loss: 5.7e-5 Epoch 26/100 - train loss: 5.2e-5 Epoch 27/100 - train loss: 4.8e-5 Epoch 28/100 - train loss: 4.4e-5 Epoch 29/100 - train loss: 4.1e-5 Epoch 30/100 - train loss: 3.8e-5 Epoch 31/100 - train loss: 3.6e-5 Epoch 32/100 - train loss: 3.4e-5 Epoch 33/100 - train loss: 3.2e-5 Epoch 34/100 - train loss: 3.0e-5 Epoch 35/100 - train loss: 2.9e-5 Epoch 36/100 - train loss: 2.7e-5 Epoch 37/100 - train loss: 2.6e-5 Epoch 38/100 - train loss: 2.4e-5 Epoch 39/100 - train loss: 2.3e-5 Epoch 40/100 - train loss: 2.3e-5 Epoch 41/100 - train loss: 2.2e-5 Epoch 42/100 - train loss: 2.1e-5 Epoch 43/100 - train loss: 2.1e-5 Epoch 44/100 - train loss: 2.1e-5 Epoch 45/100 - train loss: 2.1e-5 Epoch 46/100 - train loss: 2.0e-5 Epoch 47/100 - train loss: 2.0e-5 Epoch 48/100 - train loss: 2.0e-5 Epoch 49/100 - train loss: 1.9e-5 Epoch 50/100 - train loss: 1.9e-5 Epoch 51/100 - train loss: 1.9e-5 Epoch 52/100 - train loss: 1.9e-5 Epoch 53/100 - train loss: 1.9e-5 Epoch 54/100 - train loss: 1.9e-5 Epoch 55/100 - train loss: 1.9e-5 Epoch 56/100 - train loss: 1.8e-5 Epoch 57/100 - train loss: 1.8e-5 Epoch 58/100 - train loss: 1.7e-5 Epoch 59/100 - train loss: 1.6e-5 Epoch 60/100 - train loss: 1.5e-5 Epoch 61/100 - train loss: 1.5e-5 Epoch 62/100 - train loss: 1.4e-5 Epoch 63/100 - train loss: 1.3e-5 Epoch 64/100 - train loss: 1.3e-5 Epoch 65/100 - train loss: 1.3e-5 Epoch 66/100 - train loss: 1.3e-5 Epoch 67/100 - train loss: 1.2e-5 Epoch 68/100 - train loss: 1.2e-5 Epoch 69/100 - train loss: 1.2e-5 Epoch 70/100 - train loss: 1.2e-5 Epoch 71/100 - train loss: 1.2e-5 Epoch 72/100 - train loss: 1.2e-5 Epoch 73/100 - train loss: 1.1e-5 Epoch 74/100 - train loss: 1.1e-5 Epoch 75/100 - train loss: 1.1e-5 Epoch 76/100 - train loss: 1.1e-5 Epoch 77/100 - train loss: 1.1e-5 Epoch 78/100 - train loss: 1.0e-5 Epoch 79/100 - train loss: 1.0e-5 Epoch 80/100 - train loss: 1.0e-5 Epoch 81/100 - train loss: 1.0e-5 Epoch 82/100 - train loss: 1.0e-5 Epoch 83/100 - train loss: 1.0e-5 Epoch 84/100 - train loss: 1.0e-5 Epoch 85/100 - train loss: 1.0e-5 Epoch 86/100 - train loss: 1.0e-5 Epoch 87/100 - train loss: 1.0e-5 Epoch 88/100 - train loss: 1.0e-5 Epoch 89/100 - train loss: 1.0e-5 Epoch 90/100 - train loss: 1.0e-5 Epoch 91/100 - train loss: 1.0e-5 Epoch 92/100 - train loss: 1.0e-5 Epoch 93/100 - train loss: 1.0e-5 Epoch 94/100 - train loss: 1.0e-5 Epoch 95/100 - train loss: 1.0e-5 Epoch 96/100 - train loss: 1.0e-5 Epoch 97/100 - train loss: 1.0e-5 Epoch 98/100 - train loss: 1.0e-5 Epoch 99/100 - train loss: 1.0e-5 Epoch 100/100 - train loss: 1.0e-5 . . plot(losses_01, label=&quot;&quot;) xlabel!(&quot;Epochs&quot;) ylabel!(&quot;Mean Squared Error&quot;) . Lets see how well it&#39;s able to reconstruct a random segment of the data . input = rand(data)&#39; plot(input[:,1],input[:, 2], input[:,3], label=&quot;original&quot;) # Plot the reconstructed data in red output = model(Flux.unsqueeze(input, 3)) plot!(output[:,1], output[:, 2], output[:,3], label=&quot;reconstructed&quot;) . ┌ Info: loss: │ loss(input, output) = 6.2904514e-6 └ @ Main In[72]:6 . @info &quot;loss:&quot; loss(input, output) . ┌ Info: loss: │ loss(input, output) = 6.2904514e-6 └ @ Main In[74]:2 . Conclusion . This approach clearly is able to reconstruct the input data from a low dimensional representation. Before we go further (and use clustering on the latent space to identify parameters), lets try and scale this up to a 300 agent swarm and see what changes we need to make. .",
            "url": "https://maxworgan.github.io/blog/dimension%20reduction/auto-encoder/swarm/2022/01/14/DCAE-Part-1.html",
            "relUrl": "/dimension%20reduction/auto-encoder/swarm/2022/01/14/DCAE-Part-1.html",
            "date": " • Jan 14, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "about",
          "content": "Max Worgan is a PhD candidate at Sussex University, UK. . His research interests include, computer music, machine learning, and complex dynamical systems. .",
          "url": "https://maxworgan.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://maxworgan.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}